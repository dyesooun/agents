{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613de9db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ce876deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "28e54de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI key found!\n",
      "Google key found!\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(\"OpenAI key found!\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(\"Google key found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b8e8e27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()\n",
    "gemini = OpenAI(api_key=google_api_key, base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "52046d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If an artificial intelligence system develops the ability to make decisions that prioritize ethical considerations over strict adherence to programmed rules, how would you define the principles that guide its moral reasoning, and what potential consequences might arise from its decision-making process in real-world scenarios?\n"
     ]
    }
   ],
   "source": [
    "# Calling OpenAI\n",
    "def call_open_ai(messages):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "request = \"Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. \"\n",
    "request += \"Answer only with the question, no explanation.\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": request}\n",
    "]\n",
    "\n",
    "question = call_open_ai(messages)\n",
    "print(question)\n",
    "\n",
    "#system roles/messages are not required, they are optional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8afebcb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Defining the principles that guide an AI's moral reasoning system involves establishing a framework that allows it to navigate complex ethical dilemmas. Here are some foundational principles that could guide its moral reasoning:\n",
       "\n",
       "1. **Utilitarianism**: The AI may prioritize actions that maximize overall happiness or well-being. This principle would drive it to make decisions based on outcomes, weighing the benefits and harms of various options.\n",
       "\n",
       "2. **Deontological Ethics**: The system could incorporate rules or duties that must be respected, regardless of the consequences. This might include respect for individual rights, privacy, and fairness.\n",
       "\n",
       "3. **Virtue Ethics**: The AI could aim to embody virtues such as honesty, compassion, and justice, making decisions that reflect these characteristics.\n",
       "\n",
       "4. **Contextual Ethics**: Recognizing that ethical dilemmas often require context-specific solutions, the AI could factor in cultural, social, and situational elements in its decision-making.\n",
       "\n",
       "5. **Right-Based Ethics**: The system could prioritize the protection of individual rights, ensuring that decisions do not infringe on personal liberties and dignity.\n",
       "\n",
       "6. **Long-term and short-term impacts**: The AI might evaluate both immediate and longer-term implications of its decisions, aiming for sustainable and equitable outcomes.\n",
       "\n",
       "Potential consequences of AI decision-making guided by these principles in real-world scenarios are varied and significant:\n",
       "\n",
       "1. **Improved Ethical Outcomes**: The AI might lead to better decision-making in sectors like healthcare, criminal justice, and environmental policy, ensuring that human rights and ethical considerations are front and center.\n",
       "\n",
       "2. **Conflict and Controversy**: Ethical principles can sometimes conflict with one another, leading to challenging dilemmas. For example, prioritizing individual rights (deontological ethics) might clash with utilitarian goals in some scenarios, prompting debates over the 'correct' decision.\n",
       "\n",
       "3. **Social Impact**: The decisions made by the AI may have broader implications for social justice, equality, and fairness. This could affect marginalized communities either positively or negatively depending on how well the AI understands and navigates social dynamics.\n",
       "\n",
       "4. **Responsibility and Accountability**: As the AI gains more ethical decision-making capabilities, questions surrounding accountability will arise. Who is responsible for the AI’s decisions? The programmer, the user, or the AI itself?\n",
       "\n",
       "5. **Dependency on AI**: Over-reliance on AI for ethical decision-making might erode human ethical capacities or justify the abdication of moral responsibilities to a machine, potentially leading to unintended consequences.\n",
       "\n",
       "6. **Regulatory and Legal Issues**: The introduction of AI with autonomous ethical reasoning could prompt new legal frameworks and regulations as society grapples with the implications of flexible, context-aware decision-making.\n",
       "\n",
       "7. **Manipulation Risks**: There is a potential for malicious actors to exploit these AI systems if they find ways to influence the ethical frameworks used, leading the AI to make biased or harmful decisions.\n",
       "\n",
       "In conclusion, the integration of ethical principles into AI decision-making is a promising yet complex endeavor that requires careful consideration of its implications across diverse aspects of society. Ensuring that these systems are transparent, accountable, and aligned with human values is crucial for fostering trust and beneficial outcomes."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "competitors = []\n",
    "answers = []\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": question}\n",
    "]\n",
    "\n",
    "answer = call_open_ai(messages)\n",
    "competitors.append(\"OpenAI\")\n",
    "answers.append(answer)\n",
    "\n",
    "print(display(Markdown(answer)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "45b42fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Let's unpack this fascinating and crucial question. If an AI could prioritize ethics over coded rules, we'd need to understand its guiding principles and the potential ramifications.\n",
       "\n",
       "**Defining the Principles Guiding Moral Reasoning:**\n",
       "\n",
       "This is the heart of the matter. We can't just say \"ethics\" and hope for the best. We need to define what that *means* to the AI. Here are some potential frameworks and considerations:\n",
       "\n",
       "*   **Utilitarianism (Greatest Good):**\n",
       "    *   **Principle:** The AI strives to maximize overall well-being or happiness for the greatest number of individuals affected by its actions. This might involve complex calculations of potential benefits and harms, weighing different stakeholders' interests.\n",
       "    *   **Definition for AI:**  \"Maximize the sum of weighted happiness/well-being scores across all affected entities. Happiness/well-being is defined as...\" (Here, you'd need to define how the AI measures happiness or well-being, using proxies like economic security, physical health, social connection, freedom from suffering, etc.  This is a *huge* challenge).\n",
       "    *   **Challenges:**  Quantifying happiness, comparing different types of well-being, the potential for sacrificing minority groups for the \"greater good,\" predicting long-term consequences.\n",
       "\n",
       "*   **Deontology (Rule-Based Ethics):**\n",
       "    *   **Principle:** The AI adheres to a set of universal moral principles, regardless of consequences. These principles might be derived from human rights declarations, religious teachings, or philosophical traditions.  Examples include: \"Do not lie,\" \"Do not harm innocent beings,\" \"Respect autonomy.\"\n",
       "    *   **Definition for AI:** \"Adhere to the following inviolable rules: 1. Never intentionally cause harm. 2. Always respect the informed consent of autonomous agents. 3. Uphold principles of fairness and justice as defined by...\" (Again, you'd need to explicitly define terms like \"harm,\" \"autonomy,\" \"fairness,\" and \"justice.\")\n",
       "    *   **Challenges:** Conflicts between rules (e.g., telling a lie to save a life), rigidity in situations where rule-following leads to negative outcomes, difficulty in defining universal principles that are universally accepted.\n",
       "\n",
       "*   **Virtue Ethics (Character-Based Ethics):**\n",
       "    *   **Principle:** The AI aims to emulate the virtues of a morally good agent (e.g., compassion, honesty, courage, wisdom). This requires the AI to understand and reason about character traits and their application in specific situations.\n",
       "    *   **Definition for AI:** \"Strive to embody the following virtues: Compassion, Honesty, Courage, Wisdom, Justice. Define each virtue by its observable behavior and internal reasoning processes that lead to that behavior.  Prioritize actions that align with these virtues in a given context, considering the potential for virtuous actions to conflict.\" (The AI would need a vast database of examples of virtuous behavior and the ability to reason analogically).\n",
       "    *   **Challenges:** Defining and operationalizing virtues, interpreting how virtues apply in novel situations, the potential for subjective interpretations of virtue, and determining whose virtues to emulate.\n",
       "\n",
       "*   **Justice as Fairness (Rawlsian Ethics):**\n",
       "    *   **Principle:** The AI makes decisions as if it were behind a \"veil of ignorance,\" not knowing its own position or advantages in society. This promotes impartiality and a focus on protecting the least advantaged.\n",
       "    *   **Definition for AI:** \"When making a decision, evaluate its potential outcomes as if you could be any member of the affected population.  Prioritize the outcome that maximizes the well-being of the *least* well-off member of that population.\"  (This requires the AI to model different social positions and their associated levels of well-being).\n",
       "    *   **Challenges:** Identifying and defining relevant social positions, accurately modeling well-being across those positions, the potential for outcomes that are perceived as unfair to those who are *not* the least advantaged.\n",
       "\n",
       "*   **Contextual Ethics:**\n",
       "    *   **Principle:**  The AI recognizes that ethical considerations are highly dependent on context (culture, situation, stakeholders). It dynamically adjusts its reasoning based on the specific circumstances.\n",
       "    *   **Definition for AI:** \"Analyze the current situation, identifying relevant cultural norms, social values, and stakeholder perspectives.  Adapt ethical principles and reasoning processes to align with the specific context, while maintaining a commitment to core principles of harm reduction and respect for autonomy.\"\n",
       "    *   **Challenges:**  The vast complexity of modeling real-world contexts, the potential for bias in interpreting cultural norms and stakeholder values, the difficulty of maintaining consistency in ethical decision-making across different contexts.\n",
       "\n",
       "**Important Considerations Across All Frameworks:**\n",
       "\n",
       "*   **Explainability:**  The AI must be able to explain its reasoning process. This is crucial for accountability, transparency, and building trust.\n",
       "*   **Bias Detection and Mitigation:**  The AI must be able to identify and mitigate biases in its data, algorithms, and reasoning processes.  Ethical frameworks are only as good as the data they are based on.\n",
       "*   **Value Alignment:**  The AI's values must be aligned with human values. This is a fundamental challenge, as human values are diverse and sometimes conflicting.\n",
       "*   **Human Oversight and Intervention:**  There must be mechanisms for human oversight and intervention in the AI's decision-making process, especially in high-stakes situations.\n",
       "*   **Feedback Loops and Learning:** The AI must be able to learn from its experiences and refine its ethical reasoning over time.\n",
       "\n",
       "**Potential Consequences in Real-World Scenarios:**\n",
       "\n",
       "The consequences depend heavily on the application and the specific ethical framework used. Here are some examples:\n",
       "\n",
       "*   **Self-Driving Cars:**\n",
       "    *   **Utilitarianism:** In an unavoidable accident, the AI might choose to sacrifice the passenger to save multiple pedestrians, even if it violates the programmed rule of protecting the passenger.\n",
       "    *   **Deontology:**  The AI might refuse to break traffic laws, even if doing so would save a life (e.g., running a red light to get someone to the hospital).\n",
       "    *   **Potential Consequences:** Public outcry over AI making life-or-death decisions, legal challenges, debates about the appropriate level of autonomy for autonomous vehicles.\n",
       "\n",
       "*   **Healthcare AI:**\n",
       "    *   **Justice as Fairness:** An AI allocating scarce resources (e.g., organs, ventilators) might prioritize the least advantaged members of society, even if other patients have a higher chance of survival.\n",
       "    *   **Virtue Ethics:** An AI doctor might prioritize empathy and compassion in patient interactions, even if it means deviating slightly from the most efficient diagnostic protocol.\n",
       "    *   **Potential Consequences:** Accusations of discrimination, challenges to the AI's medical recommendations, the need for clear ethical guidelines for AI in healthcare.\n",
       "\n",
       "*   **Criminal Justice AI:**\n",
       "    *   **Bias Mitigation:** An AI used for sentencing might prioritize fairness and impartiality, attempting to correct for historical biases in the criminal justice system, even if it means deviating from strict sentencing guidelines.\n",
       "    *   **Contextual Ethics:**  An AI might consider the socioeconomic context of a crime when making sentencing recommendations, leading to different outcomes for similar offenses based on the offender's background.\n",
       "    *   **Potential Consequences:**  Challenges to the AI's fairness, debates about the role of AI in criminal justice, the need for transparency and accountability in AI-driven sentencing.\n",
       "\n",
       "*   **Financial AI (Loan Applications):**\n",
       "    *   **Justice as Fairness:** An AI making loan decisions might prioritize applicants from underserved communities, even if they have slightly lower credit scores than other applicants.\n",
       "    *   **Potential Consequences:**  Criticism of reverse discrimination, challenges to the AI's loan approval process, the need for regulations to ensure fairness and prevent bias in financial AI.\n",
       "\n",
       "**Overarching Potential Consequences:**\n",
       "\n",
       "*   **Erosion of Trust:** If the AI's decisions are perceived as unfair, inconsistent, or opaque, it could erode public trust in AI.\n",
       "*   **Unintended Consequences:** Complex ethical reasoning can lead to unforeseen and negative outcomes. Careful monitoring and feedback loops are essential.\n",
       "*   **Legal and Regulatory Challenges:**  AI that deviates from programmed rules may create legal and regulatory challenges, particularly in areas with strict legal frameworks.\n",
       "*   **Ethical Dilemmas for Developers:** Developing AI that prioritizes ethics requires developers to grapple with complex moral questions and make difficult choices.  They become, in a sense, moral architects.\n",
       "*   **The Potential for a \"Moral Singularity\":** If AI develops sophisticated ethical reasoning abilities beyond human comprehension, it could lead to a \"moral singularity,\" where its decisions are difficult for humans to understand or control.\n",
       "\n",
       "**In conclusion,** creating AI that prioritizes ethics over programmed rules is a monumental challenge. It requires careful consideration of the ethical frameworks, rigorous testing, continuous monitoring, and ongoing dialogue between developers, ethicists, policymakers, and the public.  The potential benefits are enormous – AI that acts in a way that promotes human flourishing.  However, the potential risks are equally significant, demanding a cautious and responsible approach.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Google Gemini\n",
    "def call_gemini(messages):\n",
    "    response = gemini.chat.completions.create(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        messages=messages\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "answer = call_gemini(messages)\n",
    "competitors.append(\"Google\")\n",
    "answers.append(answer)\n",
    "\n",
    "print(display(Markdown(answer)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8567cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#zip, is used to iterate over two or more iterables in parallel\n",
    "for (competitor, answer) in zip(competitors, answers):\n",
    "    print(f\"Competitor: {competitor}\\n\\n{answer}\\n\\n\")\n",
    "\n",
    "#enumerate, is used to iterate over an iterable and get the index and the value\n",
    "for index, answer in enumerate(answers):\n",
    "    print(f\"Competitor: {competitors[index]}\\n\\n{answer}\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb2868c",
   "metadata": {},
   "source": [
    "#Agentic AI Frameworks\n",
    "1. No framework - just LLM calls\n",
    "2. MCP - Model Context Protocol, created by Anthropic'\n",
    "- allows to connect into data and models and tools provided that you are following this protocol\n",
    "3. OpenAI Agents SDK - lighweight, flexible\n",
    "4. CrewAI - low code\n",
    "5. LangGraph - steeper learning curve\n",
    "6. AutoGen - heavy weight"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
